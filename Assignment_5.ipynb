{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29e7b58d-d94e-42e3-96a0-d12f7b6cd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c94385f-5a1f-4805-bbd1-0f898fe40401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 5\n"
     ]
    }
   ],
   "source": [
    "# Load your KB from a text file\n",
    "with open(\"Film_Summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    kb_text = f.read()\n",
    "\n",
    "# Simple fixed-size chunking\n",
    "chunk_size = 300\n",
    "chunks = [kb_text[i:i+chunk_size] for i in range(0, len(kb_text), chunk_size)]\n",
    "print(f\"Total chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2bfe66d-e854-4a83-9359-1fe296b20e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.10it/s]\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = embedder.encode(chunks, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# Normalize embeddings for cosine similarity search\n",
    "embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bd93937-3699-4501-a7d9-c63871c079b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index populated with 5 vectors.\n"
     ]
    }
   ],
   "source": [
    "# Determine embedding dimension\n",
    "dimension = embeddings.shape[1]\n",
    "\n",
    "# Create an index that uses Inner Product (cosine similarity for normalized vectors)\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "# Add embeddings to index\n",
    "index.add(embeddings)\n",
    "print(\"FAISS index populated with\", index.ntotal, \"vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c55e766-a8c3-4d0d-9553-65c1f5a20490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query, top_k=2):\n",
    "    # Encode and normalize query\n",
    "    query_embedding = embedder.encode([query], convert_to_numpy=True)\n",
    "    query_embedding = query_embedding / np.linalg.norm(query_embedding, axis=1, keepdims=True)\n",
    "\n",
    "    # Search for the top_k most similar chunks\n",
    "    scores, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    # Retrieve matching text chunks\n",
    "    retrieved_chunks = [chunks[i] for i in indices[0]]\n",
    "    return retrieved_chunks, scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b501bae-d495-403d-b52e-c8e11c107b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-small\"\n",
    "generator = pipeline(\"text2text-generation\", model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a87e638-79d1-4ae3-a6b1-149c45852462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query):\n",
    "    context_chunks, scores = retrieve_relevant_chunks(query, top_k=2)\n",
    "    context = \"\\n\".join(context_chunks)\n",
    "    \n",
    "    prompt = f\"Use the context below to help answer the question. If the answer cannot be inferred by the context or general knowledge, respond with 'I don't know'.\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    \n",
    "    response = generator(prompt, max_length=500, do_sample=False)\n",
    "    return response[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd740ed1-f76a-4c14-ade6-42f19eaca30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the name of the movie?\n",
      "\n",
      "Answer: Sympathy for Lady Vengeance\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the name of the movie?\"\n",
    "answer = generate_answer(query)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nAnswer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87432b8-3491-4973-a237-f7adea836deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
